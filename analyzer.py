# 2. analyzer.py - –õ–æ–≥–∏–∫–∞ –∞–Ω–∞–ª–∏–∑–∞
import fasttext
from collections import Counter, defaultdict
from data_models import JournalEntry, ImmediateAnalysis, LongTermAnalysis
import json
from datetime import datetime

class EmotionAnalyzer:
    def __init__(self):
        self.entries = []
        self.model = None

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –º–µ—Ç–æ–¥–æ–≤
        if not hasattr(self, '_generate_recommendations'):
            print("‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –ú–µ—Ç–æ–¥ _generate_recommendations –Ω–µ –Ω–∞–π–¥–µ–Ω!")

        try:
            # –ó–ê–ì–†–£–ñ–ê–ï–ú FastText-–ú–û–î–ï–õ–¨
            self.model = fasttext.load_model("model/emotion_model.bin")
        except Exception as e:
            print(f"[–û–®–ò–ë–ö–ê] –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å: {str(e)}")
            print("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª model/emotion_model.bin —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")

    def analyze_entry(self, entry_data):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç ImmediateAnalysis"""
        try:
            entry = JournalEntry(**entry_data)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–ø–∏—Å–∏: {e}")
            return None

        if not self.model:
            entry.emotion = "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
            entry.intensity = 0
            return ImmediateAnalysis(
                manifested_emotion=entry.emotion,
                intensity=entry.intensity,
                recommendation=self._generate_recommendations(entry)
            )

        try:
            labels, probs = self.model.predict(entry.text)
            entry.emotion = labels[0].replace("__label__", "")
            entry.intensity = int(probs[0] * 10)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —ç–º–æ—Ü–∏–∏: {e}")
            return None

            # üîΩ –£–±–µ–¥–∏—Å—å, —á—Ç–æ –∑–¥–µ—Å—å `entry` —É–∂–µ –µ—Å—Ç—å!
        analysis = ImmediateAnalysis(
            manifested_emotion=entry.emotion,
            intensity=entry.intensity,
            recommendation=self._generate_recommendations(entry)
        )

        self.entries.append(entry)
        return analysis

    def generate_long_term_report(self):
        if not self.entries:
            return None

        total_entries = len(self.entries)

        # –î–∏–Ω–∞–º–∏–∫–∞ —ç–º–æ—Ü–∏–π –ø–æ –¥–Ω—è–º
        emotion_by_date = defaultdict(lambda: defaultdict(int))
        for entry in self.entries:
            date = entry.timestamp.split(' ')[0]
            emotion = entry.emotion
            intensity = entry.intensity
            emotion_by_date[date][emotion] += intensity

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º defaultdict –≤ –æ–±—ã—á–Ω—ã–π dict
        emotion_trend = {d: dict(em) for d, em in emotion_by_date.items()}

        # –ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π
        emotion_counts = Counter(e.emotion for e in self.entries if hasattr(e, 'emotion'))
        most_common_emotion, count = emotion_counts.most_common(1)[0]
        emotion_percent = int(count / total_entries * 100)

        # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–∏–≥–≥–µ—Ä–æ–≤
        all_triggers = [t for e in self.entries for t in getattr(e, 'triggers', [])]
        trending_triggers = [t[0] for t in Counter(all_triggers).most_common(3)] if all_triggers else ["–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"]

        # –§–∏–∑–∏—á–µ—Å–∫–∏–µ —Å–∏–º–ø—Ç–æ–º—ã
        all_sensations = [s for e in self.entries for s in getattr(e, 'physical_sensations', [])]
        common_sensations = [s[0] for s in Counter(all_sensations).most_common(2)] if all_sensations else ["–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"]

        # –ú—ã—Å–ª–∏
        all_thoughts = [t for e in self.entries for t in getattr(e, 'thoughts', [])]
        # –û—Å–æ–∑–Ω–∞–Ω–Ω—ã–µ (—á–∞—Å—Ç—ã–µ) –º—ã—Å–ª–∏
        common_thoughts = [t[0] for t in Counter(all_thoughts).most_common(5)]

        # –§–∞–∫—Ç–æ—Ä—ã —Ä–∏—Å–∫–∞ (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –≤—ã–∑–æ–≤)
        risk_factors = self._identify_risk_factors(all_thoughts)

        return LongTermAnalysis(
            most_common_emotion=f"{most_common_emotion} ({emotion_percent}% –∑–∞–ø–∏—Å–µ–π)",
            trending_triggers=trending_triggers,
            physiological_pattern=f"–ß–∞—â–µ –≤—Å–µ–≥–æ: {', '.join(common_sensations)}",
            cognitive_pattern=f"–ß–∞—Å—Ç—ã–µ –º—ã—Å–ª–∏: {', '.join(f'¬´{t}¬ª' for t in common_thoughts)}",
            psychological_state=self._assess_mental_state(),
            risk_factors=risk_factors,
            recommendation=self._long_term_recommendations(most_common_emotion),
            emotion_trend=emotion_trend,  # üëà –ù–æ–≤–æ–µ
            risky_thoughts=common_thoughts  # üëà –ù–æ–≤–æ–µ
        )

    def _generate_recommendations(self, entry):
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∏–∑ JSON
        print(f"‚ñ∂ _generate_recommendations –≤—ã–∑–≤–∞–Ω. Entry: {entry}")
        default_rec = {
            "short_term": ["–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"],
            "scientific_references": [],
            "about": {
                "description": "–û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ",
                "causes": []
            }
        }

        try:
            with open("data/recommendations.json", encoding="utf-8") as f:
                raw = f.read().lstrip('\ufeff')  # —É–¥–∞–ª—è–µ–º BOM
                recommendations = json.loads(raw)
            result = recommendations.get(entry.emotion.lower(), default_rec)
            print("‚úî –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞–π–¥–µ–Ω—ã:", result)
            return result
        except Exception as e:
            print("–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π:", e)
            return default_rec

    def _get_common_items(self, field):
        all_items = [item for entry in self.entries for item in getattr(entry, field)]
        if not all_items:  # –ï—Å–ª–∏ —Å–ø–∏—Å–æ–∫ –ø—É—Å—Ç
            return ["–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"]
        return [item[0] for item in Counter(all_items).most_common(3)]

    def _get_pattern(self, field):
        items = self._get_common_items(field)
        return f"–ß–∞—â–µ –≤—Å–µ–≥–æ: {', '.join(items)}"

    def _assess_mental_state(self, emotion_counts=None, total_entries=None):
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–ø–∏—Å–µ–π"""
        if not hasattr(self, 'entries') or not self.entries:
            return "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ü–µ–Ω–∫–∏"

        # –ï—Å–ª–∏ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω—ã, –≤—ã—á–∏—Å–ª—è–µ–º –∏—Ö
        if emotion_counts is None or total_entries is None:
            emotion_counts = Counter(e.emotion for e in self.entries if hasattr(e, 'emotion'))
            total_entries = len(self.entries)

        # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ –æ—Ü–µ–Ω–∫–∏
        emotions = [e.emotion for e in self.entries if hasattr(e, 'emotion')]

        if emotions.count('—Å—Ç—Ä–∞—Ö') / len(emotions) > 0.5:
            return "–í–æ–∑–º–æ–∂–Ω–æ–µ —Ç—Ä–µ–≤–æ–∂–Ω–æ–µ —Ä–∞—Å—Å—Ç—Ä–æ–π—Å—Ç–≤–æ"
        elif emotions.count('–≥—Ä—É—Å—Ç—å') / len(emotions) > 0.5:
            return "–í–æ–∑–º–æ–∂–Ω–æ–µ –¥–µ–ø—Ä–µ—Å—Å–∏–≤–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ"
        elif emotions.count('–≥–Ω–µ–≤') / len(emotions) > 0.4:
            return "–ü–æ–≤—ã—à–µ–Ω–Ω–∞—è —Ä–∞–∑–¥—Ä–∞–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å"
        else:
            return "–ù–æ—Ä–º–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ"

    def _identify_risk_factors(self, thoughts=None):
        """–ë–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –≤–≤–æ–¥–∞ –∏ –≤–æ–∑–≤—Ä–∞—Ç–æ–º —Å–ª–æ–≤–∞—Ä—è"""
        if thoughts is None:
            if not hasattr(self, 'entries'):
                return {"": "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö"}
            thoughts = [t for e in self.entries for t in getattr(e, 'thoughts', [])]

        if not thoughts:
            return {"": "–ù–µ –≤—ã—è–≤–ª–µ–Ω—ã"}

        results = {}

        negative_patterns = {
            '–ø–µ—Ä—Ñ–µ–∫—Ü–∏–æ–Ω–∏–∑–º': ['–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∏–¥–µ–∞–ª—å–Ω—ã–º', '–Ω–µ –º–æ–≥—É –æ—à–∏–±–∞—Ç—å—Å—è'],
            '—Å–æ—Ü–∏–∞–ª—å–Ω–∞—è —Ç—Ä–µ–≤–æ–∂–Ω–æ—Å—Ç—å': ['–º–µ–Ω—è –æ—Å—É–¥—è—Ç', '–±—É–¥—É—Ç —Å–º–µ—è—Ç—å—Å—è'],
            '–∫–∞—Ç–∞—Å—Ç—Ä–æ—Ñ–∏–∑–∞—Ü–∏—è': ['–≤—Å–µ –±—É–¥–µ—Ç –ø–ª–æ—Ö–æ', '—ç—Ç–æ –∫–∞—Ç–∞—Å—Ç—Ä–æ—Ñ–∞'],
            '—Å–∞–º–æ–∫—Ä–∏—Ç–∏–∫–∞': ['—è –Ω–µ—É–¥–∞—á–Ω–∏–∫', '—è –Ω–∏—á–µ–≥–æ –Ω–µ —Å—Ç–æ—é'],
            '–±–µ—Å–ø–æ–º–æ—â–Ω–æ—Å—Ç—å': ['—è –Ω–µ —Å–ø—Ä–∞–≤–ª—é—Å—å', '—ç—Ç–æ –±–µ—Å–ø–æ–ª–µ–∑–Ω–æ']
        }

        for factor, patterns in negative_patterns.items():
            if any(any(pattern in thought.lower() for pattern in patterns) for thought in thoughts):
                results[factor] = f"–í—ã—Ä–∞–∂–µ–Ω—ã –º—ã—Å–ª–∏, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –ø–∞—Ç—Ç–µ—Ä–Ω–æ–º '{factor}'."

        if not results:
            return {"": "–ù–µ –≤—ã—è–≤–ª–µ–Ω—ã"}

        return results

    def _long_term_recommendations(self, emotion: str):
        return {
            "long_term": [
                "–†–µ–≥—É–ª—è—Ä–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞ –º–µ–¥–∏—Ç–∞—Ü–∏–∏",
                "–í–µ–¥–µ–Ω–∏–µ –¥–Ω–µ–≤–Ω–∏–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è"
            ],
            "professional_help": {
                "when_to_consider": "–ï—Å–ª–∏ —Å–∏–º–ø—Ç–æ–º—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –±–æ–ª–µ–µ 2 –Ω–µ–¥–µ–ª—å",
                "recommended_professionals": ["–∫–ª–∏–Ω–∏—á–µ—Å–∫–∏–π –ø—Å–∏—Ö–æ–ª–æ–≥", "–ø—Å–∏—Ö–æ—Ç–µ—Ä–∞–ø–µ–≤—Ç"],
                "resources": [
                    "https://www.psychiatry.org",
                    "https://pubmed.ncbi.nlm.nih.gov"
                ]
            }
        }